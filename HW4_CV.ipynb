{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oODWxRiiLySx"
      },
      "source": [
        "## Здесь вам необходимо решить задачу классификации изображений\n",
        "\n",
        "Решить задачу будет необходимо для 3 различных датасетов:\n",
        "\n",
        "1) MNIST - датасет изображений цифр от 0 до 10 (уже есть пример решения, оценивать будет только CIFAR+ImageNet)\n",
        "\n",
        "2) CIFAR - небольшой датасет с изображением различных объектов - максимум 5 баллов\n",
        "\n",
        "3) ImageNet - эталонный датасет для оценки моделей классификации изображений - максимум 10 баллов\n",
        "\n",
        "## Рекомендации\n",
        "\n",
        "1) Посмотреть на данные, посмотреть сбалансированность классов\n",
        "\n",
        "2) Написать класс датасета, чтобы данные можно было удобно использовать для обучения\n",
        "\n",
        "3) Написать функции обучения и валидации\n",
        "\n",
        "4) Написать/импортировать модель\n",
        "\n",
        "5) Обучить и получить неплохую метрику)\n",
        "(больше - лучше)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RTUnyYDg6Ply"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.datasets import MNIST, CIFAR10, ImageNet\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "import os, shutil\n",
        "from sklearn.metrics import *\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XV8JgjqJav-E"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m5gvz2VJ5C1"
      },
      "source": [
        "## MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "T7yMHQ7aJ6KM"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, 64, shuffle=True, drop_last=False)\n",
        "test_loader = DataLoader(test_dataset, 128, shuffle=False, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4tGalz7pPcta"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, dataloader, loss, optimizer, scheduler, device, n_epoch):\n",
        "    pbar = tqdm(dataloader, total = len(dataloader))\n",
        "    loss_p = [0, 0]\n",
        "    preds, targets = [], []\n",
        "    for (data, labels) in pbar:\n",
        "        data = data.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(data)\n",
        "        cur_loss = loss(outputs, labels)\n",
        "        loss_p[0] += cur_loss.item() * labels.shape[0]\n",
        "        loss_p[1] += labels.shape[0]\n",
        "        targets += labels.detach().cpu().numpy().tolist()\n",
        "        preds += outputs.detach().argmax(dim=1).cpu().numpy().tolist()\n",
        "        cur_loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        pbar.set_description(f\"Train_loss: {loss_p[0] / loss_p[1]}\")\n",
        "    if scheduler is not None:\n",
        "        scheduler.step()\n",
        "    return (loss_p[0] / loss_p[1], accuracy_score(targets, preds))\n",
        "\n",
        "@torch.no_grad\n",
        "def eval_epoch(model, dataloader, loss, optimizer, scheduler, device, n_epoch):\n",
        "    pbar = tqdm(dataloader, total = len(dataloader))\n",
        "    loss_p = [0, 0]\n",
        "    model.eval()\n",
        "    preds, targets = [], []\n",
        "    for (data, labels) in pbar:\n",
        "        data = data.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(data)\n",
        "        cur_loss = loss(outputs, labels)\n",
        "        loss_p[0] += cur_loss.item() * labels.shape[0]\n",
        "        loss_p[1] += labels.shape[0]\n",
        "        targets += labels.detach().cpu().numpy().tolist()\n",
        "        preds += outputs.detach().argmax(dim=1).cpu().numpy().tolist()\n",
        "        pbar.set_description(f\"Test_loss: {loss_p[0] / loss_p[1]}\")\n",
        "    return (loss_p[0] / loss_p[1], accuracy_score(targets, preds))\n",
        "\n",
        "def train_model(model, train_loader, test_loader, loss, optimizer, scheduler=None, device='cpu', n_epochs=10):\n",
        "    pbar = tqdm(range(n_epochs), total = n_epochs)\n",
        "    model = model.to(device)\n",
        "    for epoch in pbar:\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, loss, optimizer, scheduler, device, epoch)\n",
        "        test_loss, test_acc = eval_epoch(model, test_loader, loss, optimizer, scheduler, device, epoch)\n",
        "        pbar.set_description(f\"Epoch: {epoch}, Train Loss: {train_loss}, Test_loss: {test_loss}, Test Accuracy: {test_acc}\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "x4aLK2ZzPcqx"
      },
      "outputs": [],
      "source": [
        "class LinearNet(nn.Module):\n",
        "    def __init__(self, hidden_size=[784, 1024, 2048, 2048, 1024, 512, 256]):\n",
        "        super().__init__()\n",
        "        self.blocks = [nn.Sequential(\n",
        "                                      nn.Linear(hidden_size[i], hidden_size[i+1]),\n",
        "                                      nn.BatchNorm1d(hidden_size[i+1]),\n",
        "                                      nn.ReLU(), #x = max(0, x)\n",
        "                                    ) for i in range(len(hidden_size)-1)]\n",
        "        self.cls = nn.Sequential(\n",
        "            nn.Linear(hidden_size[-1], 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        x = self.cls(x)\n",
        "        return x\n",
        "\n",
        "model = LinearNet()\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = None\n",
        "device = 'cpu'\n",
        "n_epochs=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yvCxjBiGPck9"
      },
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, hidden_size=[1, 3, 8, 16, 16, 16, 8, 4]):\n",
        "        super().__init__()\n",
        "        self.blocks = [nn.Sequential(\n",
        "                                      nn.Conv2d(hidden_size[i], hidden_size[i+1], kernel_size=5, padding=2),\n",
        "                                      nn.BatchNorm2d(hidden_size[i+1]),\n",
        "                                      nn.ReLU(), #x = max(0, x)\n",
        "                                    ) for i in range(len(hidden_size)-1)]\n",
        "        self.cls = nn.Sequential(\n",
        "            nn.Linear(hidden_size[-1]*784, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        for block in self.blocks:\n",
        "            y = block(x)\n",
        "            if y.shape == x.shape:\n",
        "                x = y + x\n",
        "            else:\n",
        "                x = y\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.cls(x)\n",
        "        return x\n",
        "\n",
        "model = ConvNet()\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = None\n",
        "device = 'cpu'\n",
        "n_epochs=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35Wpcko2Pcik"
      },
      "outputs": [],
      "source": [
        "train_model(model, train_loader, test_loader, loss, optimizer, scheduler, device, n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LPCwTvp6Pcf4"
      },
      "outputs": [],
      "source": [
        "model = torchvision.models.resnet18()\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = None\n",
        "device = 'cpu'\n",
        "n_epochs=5\n",
        "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
        "model.fc = nn.Linear(512, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HLnLuTaPcdc"
      },
      "outputs": [],
      "source": [
        "train_model(model, train_loader, test_loader, loss, optimizer, scheduler, device, n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qIVMgXwbCjC"
      },
      "source": [
        "## CIFAR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bYxdI4XX3nEw"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7ky7OWcU3pTI"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "d9tfGbe_4KPj"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "4lsTgCny4PmQ"
      },
      "outputs": [],
      "source": [
        "class CIFARModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 4 * 4, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "s6mafuP44RqT"
      },
      "outputs": [],
      "source": [
        "model = CIFARModel().to(device)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "n_epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2z8FY12F4XCJ"
      },
      "outputs": [],
      "source": [
        "model = train_model(model, train_loader, test_loader, loss, optimizer, device=device, n_epochs=n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SULEnmHJ9JF"
      },
      "source": [
        "## ImageNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOsWfuCoGDA4"
      },
      "source": [
        "**Примечание:** я решил использовать TinyImageNet, т.к. не хотел загружать 155ГБ архив с Kaggle. PyTotch в Google Colab не поддерживал напрямую TinyImageNet, так что я загрузил его отдельным архивом."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KG8sI2yG-JN-"
      },
      "outputs": [],
      "source": [
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip -P ./data\n",
        "!unzip ./data/tiny-imagenet-200.zip -d ./data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "F76BY3f49qVm"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "u3QrnlPLDdrI"
      },
      "outputs": [],
      "source": [
        "class TinyImageNetDataset(Dataset):\n",
        "    def __init__(self, root, split='train', transform=None):\n",
        "        self.root = os.path.join(root, 'tiny-imagenet-200')\n",
        "        self.transform = transform\n",
        "        self.split = split\n",
        "        self.class_to_idx = {}\n",
        "\n",
        "        with open(os.path.join(self.root, 'wnids.txt'), 'r') as f:\n",
        "            self.classes = [line.strip() for line in f]\n",
        "\n",
        "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
        "\n",
        "        if split == 'train':\n",
        "            self.images = []\n",
        "            for class_name in self.classes:\n",
        "                class_dir = os.path.join(self.root, 'train', class_name, 'images')\n",
        "                for img_name in os.listdir(class_dir):\n",
        "                    self.images.append((\n",
        "                        os.path.join(class_dir, img_name),\n",
        "                        class_name\n",
        "                    ))\n",
        "        else:\n",
        "            self.images = []\n",
        "            with open(os.path.join(self.root, 'val', 'val_annotations.txt'), 'r') as f:\n",
        "                for line in f:\n",
        "                    parts = line.strip().split('\\t')\n",
        "                    img_name = parts[0]\n",
        "                    class_name = parts[1]\n",
        "                    img_path = os.path.join(self.root, 'val', 'images', img_name)\n",
        "                    self.images.append((img_path, class_name))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, class_name = self.images[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = self.class_to_idx[class_name]\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "ErakTq7fJ-i8"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "dT3vQ3ey5Iy1"
      },
      "outputs": [],
      "source": [
        "train_dataset = TinyImageNetDataset(root='./data', split='train', transform=transform)\n",
        "val_dataset = TinyImageNetDataset(root='./data', split='val', transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "V7j7NCNH5K2B"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmLr3w9q5O9N"
      },
      "outputs": [],
      "source": [
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 200)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "KW39hpHU5WKU"
      },
      "outputs": [],
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "n_epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Swxr_IaQHlq"
      },
      "outputs": [],
      "source": [
        "model = train_model(model, train_loader, test_loader, loss, optimizer, device=device, n_epochs=n_epochs)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
